/* tslint:disable */
/* eslint-disable */
/**
 * Pieces Isomorphic OpenAPI
 * Endpoints for Assets, Formats, Users, Asset, Format, User.
 *
 * The version of the OpenAPI document: 1.0
 * Contact: tsavo@pieces.app
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
import type { ByteDescriptor } from './ByteDescriptor';
import {
    ByteDescriptorFromJSON,
    ByteDescriptorFromJSONTyped,
    ByteDescriptorToJSON,
} from './ByteDescriptor';
import type { EmbeddedModelSchema } from './EmbeddedModelSchema';
import {
    EmbeddedModelSchemaFromJSON,
    EmbeddedModelSchemaFromJSONTyped,
    EmbeddedModelSchemaToJSON,
} from './EmbeddedModelSchema';
import type { ExternalMLProviderEnum } from './ExternalMLProviderEnum';
import {
    ExternalMLProviderEnumFromJSON,
    ExternalMLProviderEnumFromJSONTyped,
    ExternalMLProviderEnumToJSON,
} from './ExternalMLProviderEnum';
import type { GroupedTimestamp } from './GroupedTimestamp';
import {
    GroupedTimestampFromJSON,
    GroupedTimestampFromJSONTyped,
    GroupedTimestampToJSON,
} from './GroupedTimestamp';
import type { ModelFoundationEnum } from './ModelFoundationEnum';
import {
    ModelFoundationEnumFromJSON,
    ModelFoundationEnumFromJSONTyped,
    ModelFoundationEnumToJSON,
} from './ModelFoundationEnum';
import type { ModelMaxTokens } from './ModelMaxTokens';
import {
    ModelMaxTokensFromJSON,
    ModelMaxTokensFromJSONTyped,
    ModelMaxTokensToJSON,
} from './ModelMaxTokens';
import type { ModelTypeEnum } from './ModelTypeEnum';
import {
    ModelTypeEnumFromJSON,
    ModelTypeEnumFromJSONTyped,
    ModelTypeEnumToJSON,
} from './ModelTypeEnum';
import type { ModelUsageEnum } from './ModelUsageEnum';
import {
    ModelUsageEnumFromJSON,
    ModelUsageEnumFromJSONTyped,
    ModelUsageEnumToJSON,
} from './ModelUsageEnum';

/**
 * This is Precursor to a Model.
 * 
 * bytes: here is the size of the model in a file local on your computer.
 * ram: is the amount of ram usage when the model is loaded into memory.
 * @export
 * @interface SeededModel
 */
export interface SeededModel {
    /**
     * 
     * @type {EmbeddedModelSchema}
     * @memberof SeededModel
     */
    schema?: EmbeddedModelSchema;
    /**
     * this is a version of the model.
     * @type {string}
     * @memberof SeededModel
     */
    version: string;
    /**
     * 
     * @type {GroupedTimestamp}
     * @memberof SeededModel
     */
    created: GroupedTimestamp;
    /**
     * This is an Optional Name of the Model.
     * @type {string}
     * @memberof SeededModel
     */
    name: string;
    /**
     * An Optional Description of the model itself.
     * @type {string}
     * @memberof SeededModel
     */
    description?: string;
    /**
     * This will inform the user if this was a model that is hosted in the cloud
     * @type {boolean}
     * @memberof SeededModel
     */
    cloud: boolean;
    /**
     * 
     * @type {ModelTypeEnum}
     * @memberof SeededModel
     */
    type: ModelTypeEnum;
    /**
     * 
     * @type {ModelUsageEnum}
     * @memberof SeededModel
     */
    usage: ModelUsageEnum;
    /**
     * 
     * @type {ByteDescriptor}
     * @memberof SeededModel
     */
    bytes?: ByteDescriptor;
    /**
     * 
     * @type {ByteDescriptor}
     * @memberof SeededModel
     */
    ram?: ByteDescriptor;
    /**
     * quantization is a string like: q8f16_0,  q4f16_1, etc...
     * @type {string}
     * @memberof SeededModel
     */
    quantization?: string;
    /**
     * 
     * @type {ModelFoundationEnum}
     * @memberof SeededModel
     */
    foundation?: ModelFoundationEnum;
    /**
     * This is an optional bool to let us know if this model has been downloaded locally.
     * @type {boolean}
     * @memberof SeededModel
     */
    downloaded?: boolean;
    /**
     * This is the unique model name used to load the model.
     * @type {string}
     * @memberof SeededModel
     */
    unique?: string;
    /**
     * This is the number of parameters in terms of billions.
     * @type {number}
     * @memberof SeededModel
     */
    parameters?: number;
    /**
     * 
     * @type {ExternalMLProviderEnum}
     * @memberof SeededModel
     */
    provider?: ExternalMLProviderEnum;
    /**
     * This is an optional bool that is optimized for CPU usage.
     * @type {boolean}
     * @memberof SeededModel
     */
    cpu?: boolean;
    /**
     * 
     * @type {ModelMaxTokens}
     * @memberof SeededModel
     */
    maxTokens?: ModelMaxTokens;
    /**
     * This is reserved to custommly registed models.
     * @type {boolean}
     * @memberof SeededModel
     */
    custom?: boolean;
}

/**
 * Check if a given object implements the SeededModel interface.
 */
export function instanceOfSeededModel(value: object): boolean {
    if (!('version' in value)) return false;
    if (!('created' in value)) return false;
    if (!('name' in value)) return false;
    if (!('cloud' in value)) return false;
    if (!('type' in value)) return false;
    if (!('usage' in value)) return false;
    return true;
}

export function SeededModelFromJSON(json: any): SeededModel {
    return SeededModelFromJSONTyped(json, false);
}

export function SeededModelFromJSONTyped(json: any, ignoreDiscriminator: boolean): SeededModel {
    if (json == null) {
        return json;
    }
    return {
        
        'schema': json['schema'] == null ? undefined : EmbeddedModelSchemaFromJSON(json['schema']),
        'version': json['version'],
        'created': GroupedTimestampFromJSON(json['created']),
        'name': json['name'],
        'description': json['description'] == null ? undefined : json['description'],
        'cloud': json['cloud'],
        'type': ModelTypeEnumFromJSON(json['type']),
        'usage': ModelUsageEnumFromJSON(json['usage']),
        'bytes': json['bytes'] == null ? undefined : ByteDescriptorFromJSON(json['bytes']),
        'ram': json['ram'] == null ? undefined : ByteDescriptorFromJSON(json['ram']),
        'quantization': json['quantization'] == null ? undefined : json['quantization'],
        'foundation': json['foundation'] == null ? undefined : ModelFoundationEnumFromJSON(json['foundation']),
        'downloaded': json['downloaded'] == null ? undefined : json['downloaded'],
        'unique': json['unique'] == null ? undefined : json['unique'],
        'parameters': json['parameters'] == null ? undefined : json['parameters'],
        'provider': json['provider'] == null ? undefined : ExternalMLProviderEnumFromJSON(json['provider']),
        'cpu': json['cpu'] == null ? undefined : json['cpu'],
        'maxTokens': json['maxTokens'] == null ? undefined : ModelMaxTokensFromJSON(json['maxTokens']),
        'custom': json['custom'] == null ? undefined : json['custom'],
    };
}

export function SeededModelToJSON(value?: SeededModel | null): any {
    if (value == null) {
        return value;
    }
    return {
        
        'schema': EmbeddedModelSchemaToJSON(value['schema']),
        'version': value['version'],
        'created': GroupedTimestampToJSON(value['created']),
        'name': value['name'],
        'description': value['description'],
        'cloud': value['cloud'],
        'type': ModelTypeEnumToJSON(value['type']),
        'usage': ModelUsageEnumToJSON(value['usage']),
        'bytes': ByteDescriptorToJSON(value['bytes']),
        'ram': ByteDescriptorToJSON(value['ram']),
        'quantization': value['quantization'],
        'foundation': ModelFoundationEnumToJSON(value['foundation']),
        'downloaded': value['downloaded'],
        'unique': value['unique'],
        'parameters': value['parameters'],
        'provider': ExternalMLProviderEnumToJSON(value['provider']),
        'cpu': value['cpu'],
        'maxTokens': ModelMaxTokensToJSON(value['maxTokens']),
        'custom': value['custom'],
    };
}

